{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJh7qtest0Vp006vPSrfXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhaj-mhd/two-tower-recommedation/blob/main/two_tower_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6rQ19NkZo8s",
        "outputId": "f3e06e54-47fe-4f27-a871-4872b63a5bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Installing and upgrading all required packages...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "✅ All packages have been installed and upgraded.\n"
          ]
        }
      ],
      "source": [
        "print(\"⏳ Installing and upgrading all required packages...\")\n",
        "\n",
        "%pip install --upgrade -q tensorflow tensorflow-recommenders tf-keras tensorflow-text\n",
        "%pip install -q faiss-cpu\n",
        "\n",
        "print(\"\\n✅ All packages have been installed and upgraded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade -q tensorflow-decision-forests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbdXsqBCabJ4",
        "outputId": "c609ac5f-d8cc-41c8-9230-90a07d4a94d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tf_keras\n",
        "import faiss\n",
        "import tensorflow_text as tf_text\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "print(f\"tensorflow: {tf.__version__}\")\n",
        "print(f\"tensorflow-recommenders: {tfrs.__version__}\")\n",
        "print(f\"tf-keras: {tf_keras.__version__}\")\n",
        "print(f\"faiss-cpu: {faiss.__version__}\")\n",
        "print(f\"tensorflow-text: {tf_text.__version__}\")\n",
        "print(f\"tensorflow-decision-forests: {tfdf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "_roixOESalk5",
        "outputId": "a8a783f8-e0f6-400f-9efe-fb19aebe2eed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'float8_e4m3b11fnuz' from 'tensorflow.python.framework.dtypes' (/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-855599773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_recommenders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor_api\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/dtensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/compat/v2/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masync_scope\u001b[0m \u001b[0;31m# line: 3054\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction_executor_type\u001b[0m \u001b[0;31m# line: 2903\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloat8_e4m3b11fnuz\u001b[0m \u001b[0;31m# line: 465\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloat8_e4m3fn\u001b[0m \u001b[0;31m# line: 439\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloat8_e4m3fnuz\u001b[0m \u001b[0;31m# line: 452\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'float8_e4m3b11fnuz' from 'tensorflow.python.framework.dtypes' (/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import faiss\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Step 1: Fabricate Data with Category-based User Behavior ---\n",
        "print(\"[1] Fabricating data with category-based user preferences...\")\n",
        "categories = [\"gadget\", \"apparel\", \"book\", \"tool\", \"toy\", \"utensil\"]\n",
        "num_items = 5000\n",
        "num_users = 500\n",
        "\n",
        "# Create items with explicit category tracking\n",
        "item_titles = [f\"Product {i}\" for i in range(num_items)]\n",
        "item_categories = [categories[i % len(categories)] for i in range(num_items)]\n",
        "description_templates = [\n",
        "    lambda i, cat: f\"High-quality, durable {cat} for all your needs. Model v{i % 10}. Made from premium materials.\",\n",
        "    lambda i, cat: f\"An affordable and reliable {cat}. Perfect for beginners. Item #{i}.\",\n",
        "    lambda i, cat: f\"The ultimate professional-grade {cat}. Features advanced technology. SKU {i}.\",\n",
        "]\n",
        "item_descriptions = [description_templates[i % 3](i, item_categories[i]) for i in range(num_items)]\n",
        "\n",
        "items_data = {\n",
        "    \"item_id\": [str(i) for i in range(num_items)],\n",
        "    \"item_title\": item_titles,\n",
        "    \"item_description\": item_descriptions,\n",
        "    \"category\": item_categories\n",
        "}\n",
        "items_df = pd.DataFrame(items_data)\n",
        "\n",
        "# Create category-to-items mapping for easier lookup\n",
        "category_to_items = defaultdict(list)\n",
        "for idx, row in items_df.iterrows():\n",
        "    category_to_items[row['category']].append(row['item_id'])\n",
        "\n",
        "# Generate user interactions: each user interacts with exactly 2 categories\n",
        "print(\"Generating user interactions with category preferences...\")\n",
        "user_interactions = []\n",
        "user_categories = {}  # Track which categories each user prefers\n",
        "\n",
        "for user_id in range(num_users):\n",
        "    # Each user randomly selects 2 categories\n",
        "    preferred_categories = np.random.choice(categories, size=2, replace=False)\n",
        "    user_categories[str(user_id)] = preferred_categories\n",
        "\n",
        "    # Generate 10 interactions for this user (5 from each category)\n",
        "    for category in preferred_categories:\n",
        "        # Select 5 random items from this category\n",
        "        available_items = category_to_items[category]\n",
        "        selected_items = np.random.choice(available_items, size=5, replace=True)\n",
        "\n",
        "        for item_id in selected_items:\n",
        "            user_interactions.append({\n",
        "                \"user_id\": str(user_id),\n",
        "                \"item_id\": item_id\n",
        "            })\n",
        "\n",
        "interactions_df = pd.DataFrame(user_interactions)\n",
        "print(f\"Generated {len(items_df)} items and {len(interactions_df)} interactions.\")\n",
        "print(f\"Each user interacts with exactly 2 categories out of {len(categories)} total categories.\")\n",
        "\n",
        "# Display some user preferences for verification\n",
        "print(\"\\nSample user category preferences:\")\n",
        "for i in range(5):\n",
        "    user_id = str(i)\n",
        "    print(f\"User {user_id}: {user_categories[user_id]}\")\n",
        "\n",
        "items_ds = tf.data.Dataset.from_tensor_slices(dict(items_df))\n",
        "\n",
        "# --- Step 2: Self-Supervised Item Tower ---\n",
        "print(\"\\n[2] Building and training the self-supervised Item Tower...\")\n",
        "embedding_dimension = 32\n",
        "max_tokens = 10_000\n",
        "sequence_length = 100\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, output_sequence_length=sequence_length)\n",
        "text_vectorizer.adapt(items_ds.map(lambda x: x[\"item_description\"]).batch(128))\n",
        "\n",
        "class ItemModel(tf.keras.Model):\n",
        "    def __init__(self, vectorizer):\n",
        "        super().__init__()\n",
        "        self.vectorizer = vectorizer\n",
        "        self.embedding = tf.keras.Sequential([\n",
        "            self.vectorizer,\n",
        "            tf.keras.layers.Embedding(input_dim=self.vectorizer.vocabulary_size(), output_dim=embedding_dimension, mask_zero=True),\n",
        "            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        ])\n",
        "        self.dense = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embedding_dimension)\n",
        "        ])\n",
        "    def call(self, inputs):\n",
        "        return self.dense(self.embedding(inputs[\"item_description\"]))\n",
        "\n",
        "class SelfSupervisedItemTwoTower(tfrs.Model):\n",
        "    def __init__(self, item_model):\n",
        "        super().__init__()\n",
        "        self.item_model = item_model\n",
        "        self.task = tfrs.tasks.Retrieval()\n",
        "    def compute_loss(self, features, training=False):\n",
        "        item_embeddings = self.item_model(features)\n",
        "        return self.task(query_embeddings=item_embeddings, candidate_embeddings=item_embeddings)\n",
        "\n",
        "item_tower = ItemModel(text_vectorizer)\n",
        "item_model_trainer = SelfSupervisedItemTwoTower(item_tower)\n",
        "item_model_trainer.compile(optimizer=tf.keras.optimizers.Adagrad(0.05))\n",
        "train_item_ds = items_ds.map(lambda x: {\"item_description\": x[\"item_description\"]}).batch(256).cache()\n",
        "item_model_trainer.fit(train_item_ds, epochs=5)\n",
        "print(\"Item Tower training complete.\")\n",
        "\n",
        "# --- Step 3: Generate and Store Item Embeddings in Faiss ---\n",
        "print(\"\\n[3] Generating item embeddings and storing in Faiss...\")\n",
        "index = faiss.IndexFlatL2(embedding_dimension)\n",
        "item_embeddings_generator = items_ds.batch(256).map(lambda x: item_tower(x))\n",
        "all_item_embeddings = np.concatenate(list(item_embeddings_generator.as_numpy_iterator()))\n",
        "index.add(all_item_embeddings)\n",
        "print(f\"Faiss index now contains {index.ntotal} vectors.\")\n",
        "index_to_item_id = {i: item_id for i, item_id in enumerate(items_df[\"item_id\"])}\n",
        "\n",
        "# --- Step 4: Train the User Tower ---\n",
        "print(\"\\n[4] Building and training the User Tower...\")\n",
        "unique_user_ids = interactions_df[\"user_id\"].unique()\n",
        "\n",
        "class UserModel(tf.keras.Model):\n",
        "    def __init__(self, user_ids):\n",
        "        super().__init__()\n",
        "        self.user_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(vocabulary=user_ids, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(user_ids) + 1, embedding_dimension)\n",
        "        ])\n",
        "        self.dense = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(embedding_dimension)\n",
        "        ])\n",
        "    def call(self, inputs):\n",
        "        return self.dense(self.user_embedding(inputs))\n",
        "\n",
        "class UserItemRetrievalModel(tfrs.Model):\n",
        "    def __init__(self, user_model, item_model):\n",
        "        super().__init__()\n",
        "        self.user_model = user_model\n",
        "        self.item_model = item_model\n",
        "        self.item_model.trainable = False  # Keep item model frozen\n",
        "\n",
        "        # Simple retrieval task\n",
        "        self.task = tfrs.tasks.Retrieval()\n",
        "\n",
        "    def compute_loss(self, data, training=False):\n",
        "        user_embeddings = self.user_model(data[\"user_id\"])\n",
        "\n",
        "        # Get item embeddings for the interacted items\n",
        "        item_data = {\"item_description\": data[\"item_description\"]}\n",
        "        item_embeddings = self.item_model(item_data)\n",
        "\n",
        "        return self.task(\n",
        "            query_embeddings=user_embeddings,\n",
        "            candidate_embeddings=item_embeddings\n",
        "        )\n",
        "\n",
        "# Prepare training data with item descriptions and categories\n",
        "interactions_with_details_df = pd.merge(\n",
        "    interactions_df,\n",
        "    items_df[['item_id', 'item_description', 'category']],\n",
        "    on='item_id'\n",
        ")\n",
        "full_interactions_ds = tf.data.Dataset.from_tensor_slices(dict(interactions_with_details_df))\n",
        "train_ds_user = full_interactions_ds.shuffle(10_000).batch(256).cache()\n",
        "\n",
        "user_tower = UserModel(unique_user_ids)\n",
        "user_model_trainer = UserItemRetrievalModel(user_tower, item_tower)\n",
        "user_model_trainer.compile(optimizer=tf.keras.optimizers.Adagrad(0.05))\n",
        "\n",
        "# Train the user model\n",
        "user_model_trainer.fit(train_ds_user, epochs=5)\n",
        "print(\"User Tower training complete.\")\n",
        "\n",
        "# --- Step 5: Serve and Validate Recommendations ---\n",
        "print(\"\\n[5] Serving and validating recommendations...\")\n",
        "\n",
        "def get_recommendations_with_validation(user_id, top_k=10):\n",
        "    print(f\"\\n--- Getting recommendations for user '{user_id}' ---\")\n",
        "\n",
        "    if user_id not in unique_user_ids:\n",
        "        print(f\"User '{user_id}' is a new user (cold start).\")\n",
        "        return\n",
        "\n",
        "    # Get user's preferred categories\n",
        "    preferred_categories = user_categories[user_id]\n",
        "    print(f\"User's preferred categories: {preferred_categories}\")\n",
        "\n",
        "    # Get user embedding and find similar items\n",
        "    user_embedding = user_tower(tf.constant([user_id])).numpy()\n",
        "    distances, indices = index.search(user_embedding, top_k)\n",
        "\n",
        "    print(f\"Top {top_k} recommendations:\")\n",
        "    category_counts = defaultdict(int)\n",
        "\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        item_id = index_to_item_id[idx]\n",
        "        item_row = items_df[items_df['item_id'] == item_id].iloc[0]\n",
        "        item_title = item_row['item_title']\n",
        "        item_category = item_row['category']\n",
        "        category_counts[item_category] += 1\n",
        "\n",
        "        # Mark if recommendation matches user's preferences\n",
        "        is_preferred = \"✓\" if item_category in preferred_categories else \"✗\"\n",
        "        print(f\"  {i+1}. {is_preferred} Item ID: {item_id} | Category: {item_category} | Title: '{item_title}' (Distance: {distances[0][i]:.4f})\")\n",
        "\n",
        "    # Calculate recommendation accuracy\n",
        "    correct_recommendations = sum(category_counts[cat] for cat in preferred_categories)\n",
        "    accuracy = correct_recommendations / top_k\n",
        "\n",
        "    print(f\"\\n--- Recommendation Analysis ---\")\n",
        "    print(f\"Category distribution in recommendations:\")\n",
        "    for category, count in category_counts.items():\n",
        "        percentage = (count / top_k) * 100\n",
        "        is_preferred = \"✓\" if category in preferred_categories else \"✗\"\n",
        "        print(f\"  {is_preferred} {category}: {count}/{top_k} ({percentage:.1f}%)\")\n",
        "\n",
        "    print(f\"Accuracy: {correct_recommendations}/{top_k} ({accuracy:.1%}) recommendations match user preferences\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Test recommendations for several users\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING RECOMMENDATION ACCURACY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "accuracies = []\n",
        "test_users = [\"0\", \"1\", \"2\", \"3\", \"4\", \"10\", \"25\", \"50\"]\n",
        "\n",
        "for user_id in test_users:\n",
        "    if user_id in unique_user_ids:\n",
        "        accuracy = get_recommendations_with_validation(user_id)\n",
        "        if accuracy is not None:\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "if accuracies:\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"OVERALL RESULTS\")\n",
        "    print(f\"=\"*60)\n",
        "    print(f\"Average recommendation accuracy: {avg_accuracy:.1%}\")\n",
        "    print(f\"Tested {len(accuracies)} users\")\n",
        "\n",
        "    if avg_accuracy > 0.7:\n",
        "        print(\"✓ Good performance! Most recommendations match user preferences.\")\n",
        "    elif avg_accuracy > 0.5:\n",
        "        print(\"~ Moderate performance. Some recommendations match user preferences.\")\n",
        "    else:\n",
        "        print(\"✗ Poor performance. Few recommendations match user preferences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlwTsIUjaz4S",
        "outputId": "9bba54bf-553a-4c76-9282-417d29c09aaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Fabricating data with category-based user preferences...\n",
            "Generating user interactions with category preferences...\n",
            "Generated 5000 items and 5000 interactions.\n",
            "Each user interacts with exactly 2 categories out of 6 total categories.\n",
            "\n",
            "Sample user category preferences:\n",
            "User 0: ['utensil' 'gadget']\n",
            "User 1: ['book' 'apparel']\n",
            "User 2: ['tool' 'toy']\n",
            "User 3: ['toy' 'tool']\n",
            "User 4: ['toy' 'tool']\n",
            "\n",
            "[2] Building and training the self-supervised Item Tower...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 1313.1624 - regularization_loss: 0.0000e+00 - total_loss: 1313.1624\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1005.8630 - regularization_loss: 0.0000e+00 - total_loss: 1005.8630\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 968.2358 - regularization_loss: 0.0000e+00 - total_loss: 968.2358  \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 928.0807 - regularization_loss: 0.0000e+00 - total_loss: 928.0807\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 911.0480 - regularization_loss: 0.0000e+00 - total_loss: 911.0480\n",
            "Item Tower training complete.\n",
            "\n",
            "[3] Generating item embeddings and storing in Faiss...\n",
            "Faiss index now contains 5000 vectors.\n",
            "\n",
            "[4] Building and training the User Tower...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 1300.7311 - regularization_loss: 0.0000e+00 - total_loss: 1300.7311\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1178.3768 - regularization_loss: 0.0000e+00 - total_loss: 1178.3768\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1144.8716 - regularization_loss: 0.0000e+00 - total_loss: 1144.8716\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1128.2761 - regularization_loss: 0.0000e+00 - total_loss: 1128.2761\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1123.4067 - regularization_loss: 0.0000e+00 - total_loss: 1123.4067\n",
            "User Tower training complete.\n",
            "\n",
            "[5] Serving and validating recommendations...\n",
            "\n",
            "============================================================\n",
            "TESTING RECOMMENDATION ACCURACY\n",
            "============================================================\n",
            "\n",
            "--- Getting recommendations for user '0' ---\n",
            "User's preferred categories: ['utensil' 'gadget']\n",
            "Top 10 recommendations:\n",
            "  1. ✓ Item ID: 6 | Category: gadget | Title: 'Product 6' (Distance: 9.8030)\n",
            "  2. ✓ Item ID: 36 | Category: gadget | Title: 'Product 36' (Distance: 9.8030)\n",
            "  3. ✓ Item ID: 66 | Category: gadget | Title: 'Product 66' (Distance: 9.8030)\n",
            "  4. ✓ Item ID: 96 | Category: gadget | Title: 'Product 96' (Distance: 9.8030)\n",
            "  5. ✓ Item ID: 126 | Category: gadget | Title: 'Product 126' (Distance: 9.8030)\n",
            "  6. ✓ Item ID: 156 | Category: gadget | Title: 'Product 156' (Distance: 9.8030)\n",
            "  7. ✓ Item ID: 186 | Category: gadget | Title: 'Product 186' (Distance: 9.8030)\n",
            "  8. ✓ Item ID: 216 | Category: gadget | Title: 'Product 216' (Distance: 9.8030)\n",
            "  9. ✓ Item ID: 246 | Category: gadget | Title: 'Product 246' (Distance: 9.8030)\n",
            "  10. ✓ Item ID: 276 | Category: gadget | Title: 'Product 276' (Distance: 9.8030)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✓ gadget: 10/10 (100.0%)\n",
            "  ✓ utensil: 0/10 (0.0%)\n",
            "Accuracy: 10/10 (100.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '1' ---\n",
            "User's preferred categories: ['book' 'apparel']\n",
            "Top 10 recommendations:\n",
            "  1. ✓ Item ID: 781 | Category: apparel | Title: 'Product 781' (Distance: 23.9477)\n",
            "  2. ✓ Item ID: 829 | Category: apparel | Title: 'Product 829' (Distance: 23.9605)\n",
            "  3. ✓ Item ID: 865 | Category: apparel | Title: 'Product 865' (Distance: 23.9659)\n",
            "  4. ✓ Item ID: 841 | Category: apparel | Title: 'Product 841' (Distance: 23.9733)\n",
            "  5. ✓ Item ID: 775 | Category: apparel | Title: 'Product 775' (Distance: 23.9734)\n",
            "  6. ✓ Item ID: 2761 | Category: apparel | Title: 'Product 2761' (Distance: 23.9771)\n",
            "  7. ✓ Item ID: 2659 | Category: apparel | Title: 'Product 2659' (Distance: 23.9777)\n",
            "  8. ✓ Item ID: 931 | Category: apparel | Title: 'Product 931' (Distance: 23.9904)\n",
            "  9. ✓ Item ID: 1003 | Category: apparel | Title: 'Product 1003' (Distance: 23.9924)\n",
            "  10. ✓ Item ID: 3499 | Category: apparel | Title: 'Product 3499' (Distance: 23.9950)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✓ apparel: 10/10 (100.0%)\n",
            "  ✓ book: 0/10 (0.0%)\n",
            "Accuracy: 10/10 (100.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '2' ---\n",
            "User's preferred categories: ['tool' 'toy']\n",
            "Top 10 recommendations:\n",
            "  1. ✗ Item ID: 12 | Category: gadget | Title: 'Product 12' (Distance: 12.3404)\n",
            "  2. ✗ Item ID: 42 | Category: gadget | Title: 'Product 42' (Distance: 12.3404)\n",
            "  3. ✗ Item ID: 72 | Category: gadget | Title: 'Product 72' (Distance: 12.3404)\n",
            "  4. ✗ Item ID: 102 | Category: gadget | Title: 'Product 102' (Distance: 12.3404)\n",
            "  5. ✗ Item ID: 132 | Category: gadget | Title: 'Product 132' (Distance: 12.3404)\n",
            "  6. ✗ Item ID: 162 | Category: gadget | Title: 'Product 162' (Distance: 12.3404)\n",
            "  7. ✗ Item ID: 192 | Category: gadget | Title: 'Product 192' (Distance: 12.3404)\n",
            "  8. ✗ Item ID: 222 | Category: gadget | Title: 'Product 222' (Distance: 12.3404)\n",
            "  9. ✗ Item ID: 252 | Category: gadget | Title: 'Product 252' (Distance: 12.3404)\n",
            "  10. ✗ Item ID: 282 | Category: gadget | Title: 'Product 282' (Distance: 12.3404)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✗ gadget: 10/10 (100.0%)\n",
            "  ✓ tool: 0/10 (0.0%)\n",
            "  ✓ toy: 0/10 (0.0%)\n",
            "Accuracy: 0/10 (0.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '3' ---\n",
            "User's preferred categories: ['toy' 'tool']\n",
            "Top 10 recommendations:\n",
            "  1. ✗ Item ID: 12 | Category: gadget | Title: 'Product 12' (Distance: 11.9918)\n",
            "  2. ✗ Item ID: 42 | Category: gadget | Title: 'Product 42' (Distance: 11.9918)\n",
            "  3. ✗ Item ID: 72 | Category: gadget | Title: 'Product 72' (Distance: 11.9918)\n",
            "  4. ✗ Item ID: 102 | Category: gadget | Title: 'Product 102' (Distance: 11.9918)\n",
            "  5. ✗ Item ID: 132 | Category: gadget | Title: 'Product 132' (Distance: 11.9918)\n",
            "  6. ✗ Item ID: 162 | Category: gadget | Title: 'Product 162' (Distance: 11.9918)\n",
            "  7. ✗ Item ID: 192 | Category: gadget | Title: 'Product 192' (Distance: 11.9918)\n",
            "  8. ✗ Item ID: 222 | Category: gadget | Title: 'Product 222' (Distance: 11.9918)\n",
            "  9. ✗ Item ID: 252 | Category: gadget | Title: 'Product 252' (Distance: 11.9918)\n",
            "  10. ✗ Item ID: 282 | Category: gadget | Title: 'Product 282' (Distance: 11.9918)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✗ gadget: 10/10 (100.0%)\n",
            "  ✓ toy: 0/10 (0.0%)\n",
            "  ✓ tool: 0/10 (0.0%)\n",
            "Accuracy: 0/10 (0.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '4' ---\n",
            "User's preferred categories: ['toy' 'tool']\n",
            "Top 10 recommendations:\n",
            "  1. ✗ Item ID: 12 | Category: gadget | Title: 'Product 12' (Distance: 12.0240)\n",
            "  2. ✗ Item ID: 42 | Category: gadget | Title: 'Product 42' (Distance: 12.0240)\n",
            "  3. ✗ Item ID: 72 | Category: gadget | Title: 'Product 72' (Distance: 12.0240)\n",
            "  4. ✗ Item ID: 102 | Category: gadget | Title: 'Product 102' (Distance: 12.0240)\n",
            "  5. ✗ Item ID: 132 | Category: gadget | Title: 'Product 132' (Distance: 12.0240)\n",
            "  6. ✗ Item ID: 162 | Category: gadget | Title: 'Product 162' (Distance: 12.0240)\n",
            "  7. ✗ Item ID: 192 | Category: gadget | Title: 'Product 192' (Distance: 12.0240)\n",
            "  8. ✗ Item ID: 222 | Category: gadget | Title: 'Product 222' (Distance: 12.0240)\n",
            "  9. ✗ Item ID: 252 | Category: gadget | Title: 'Product 252' (Distance: 12.0240)\n",
            "  10. ✗ Item ID: 282 | Category: gadget | Title: 'Product 282' (Distance: 12.0240)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✗ gadget: 10/10 (100.0%)\n",
            "  ✓ toy: 0/10 (0.0%)\n",
            "  ✓ tool: 0/10 (0.0%)\n",
            "Accuracy: 0/10 (0.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '10' ---\n",
            "User's preferred categories: ['book' 'gadget']\n",
            "Top 10 recommendations:\n",
            "  1. ✓ Item ID: 12 | Category: gadget | Title: 'Product 12' (Distance: 11.5406)\n",
            "  2. ✓ Item ID: 42 | Category: gadget | Title: 'Product 42' (Distance: 11.5406)\n",
            "  3. ✓ Item ID: 72 | Category: gadget | Title: 'Product 72' (Distance: 11.5406)\n",
            "  4. ✓ Item ID: 102 | Category: gadget | Title: 'Product 102' (Distance: 11.5406)\n",
            "  5. ✓ Item ID: 132 | Category: gadget | Title: 'Product 132' (Distance: 11.5406)\n",
            "  6. ✓ Item ID: 162 | Category: gadget | Title: 'Product 162' (Distance: 11.5406)\n",
            "  7. ✓ Item ID: 192 | Category: gadget | Title: 'Product 192' (Distance: 11.5406)\n",
            "  8. ✓ Item ID: 222 | Category: gadget | Title: 'Product 222' (Distance: 11.5406)\n",
            "  9. ✓ Item ID: 252 | Category: gadget | Title: 'Product 252' (Distance: 11.5406)\n",
            "  10. ✓ Item ID: 282 | Category: gadget | Title: 'Product 282' (Distance: 11.5406)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✓ gadget: 10/10 (100.0%)\n",
            "  ✓ book: 0/10 (0.0%)\n",
            "Accuracy: 10/10 (100.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '25' ---\n",
            "User's preferred categories: ['apparel' 'book']\n",
            "Top 10 recommendations:\n",
            "  1. ✓ Item ID: 781 | Category: apparel | Title: 'Product 781' (Distance: 23.0189)\n",
            "  2. ✓ Item ID: 829 | Category: apparel | Title: 'Product 829' (Distance: 23.0302)\n",
            "  3. ✓ Item ID: 865 | Category: apparel | Title: 'Product 865' (Distance: 23.0336)\n",
            "  4. ✓ Item ID: 841 | Category: apparel | Title: 'Product 841' (Distance: 23.0422)\n",
            "  5. ✓ Item ID: 775 | Category: apparel | Title: 'Product 775' (Distance: 23.0510)\n",
            "  6. ✓ Item ID: 2659 | Category: apparel | Title: 'Product 2659' (Distance: 23.0607)\n",
            "  7. ✓ Item ID: 931 | Category: apparel | Title: 'Product 931' (Distance: 23.0614)\n",
            "  8. ✓ Item ID: 2761 | Category: apparel | Title: 'Product 2761' (Distance: 23.0617)\n",
            "  9. ✓ Item ID: 1003 | Category: apparel | Title: 'Product 1003' (Distance: 23.0679)\n",
            "  10. ✓ Item ID: 811 | Category: apparel | Title: 'Product 811' (Distance: 23.0681)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✓ apparel: 10/10 (100.0%)\n",
            "  ✓ book: 0/10 (0.0%)\n",
            "Accuracy: 10/10 (100.0%) recommendations match user preferences\n",
            "\n",
            "--- Getting recommendations for user '50' ---\n",
            "User's preferred categories: ['toy' 'book']\n",
            "Top 10 recommendations:\n",
            "  1. ✓ Item ID: 2800 | Category: toy | Title: 'Product 2800' (Distance: 13.3704)\n",
            "  2. ✓ Item ID: 1774 | Category: toy | Title: 'Product 1774' (Distance: 13.3821)\n",
            "  3. ✓ Item ID: 2200 | Category: toy | Title: 'Product 2200' (Distance: 13.3933)\n",
            "  4. ✓ Item ID: 1900 | Category: toy | Title: 'Product 1900' (Distance: 13.4090)\n",
            "  5. ✓ Item ID: 3238 | Category: toy | Title: 'Product 3238' (Distance: 13.4091)\n",
            "  6. ✓ Item ID: 2350 | Category: toy | Title: 'Product 2350' (Distance: 13.4092)\n",
            "  7. ✓ Item ID: 3268 | Category: toy | Title: 'Product 3268' (Distance: 13.4105)\n",
            "  8. ✓ Item ID: 1624 | Category: toy | Title: 'Product 1624' (Distance: 13.4123)\n",
            "  9. ✓ Item ID: 694 | Category: toy | Title: 'Product 694' (Distance: 13.4124)\n",
            "  10. ✓ Item ID: 1672 | Category: toy | Title: 'Product 1672' (Distance: 13.4128)\n",
            "\n",
            "--- Recommendation Analysis ---\n",
            "Category distribution in recommendations:\n",
            "  ✓ toy: 10/10 (100.0%)\n",
            "  ✓ book: 0/10 (0.0%)\n",
            "Accuracy: 10/10 (100.0%) recommendations match user preferences\n",
            "\n",
            "============================================================\n",
            "OVERALL RESULTS\n",
            "============================================================\n",
            "Average recommendation accuracy: 62.5%\n",
            "Tested 8 users\n",
            "~ Moderate performance. Some recommendations match user preferences.\n"
          ]
        }
      ]
    }
  ]
}